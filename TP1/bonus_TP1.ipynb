{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bonus_TP1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9yBro2t4C094"},"source":["# **TP1 (BONUS part) : le workflow universel du machine learning**"]},{"cell_type":"markdown","metadata":{"id":"CS2L61aQOLAL"},"source":["# 2. Energy consumption prediction from timeseries\n"]},{"cell_type":"markdown","metadata":{"id":"rxm4w_bKfEzt"},"source":["**Question 2.1** : for this project, we will be using the [opsd_germany_daily](https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv) dataset. You can download it using its url and the [pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method from the `pandas` library."]},{"cell_type":"markdown","metadata":{"id":"2XNqhtsQbdLK"},"source":["As you should see your dataset has been put into a pandas `DataFrame`. The library `pandas` provides a set of open source data analysis and manipulation tool built on top of the Python programming language. `pandas` tools are widely used in data sciences, especially with time series data. So before going further, you will have to get more familiar with `pandas`, take 10 mins to go through the official [tutorial](https://pandas.pydata.org/docs/user_guide/10min.html)."]},{"cell_type":"markdown","metadata":{"id":"R2qzvaMzfM_r"},"source":["## Problem definition"]},{"cell_type":"markdown","metadata":{"id":"2NZAig5qbHGA"},"source":["**Question 2.2** : please answer the following questions about the dataset:\n","\n","*   how many samples contain the dataset ? \n","*   how many variables ? what are their names ?\n"]},{"cell_type":"markdown","metadata":{"id":"FfmrDQjxQB9Y"},"source":["**Question 2.3** : in the process of defining a machine learning problem, computing summary statistics and/or visualizing different aspects of the dataset are often very useful. \n","\n","*   Compute summary statistics to describe the dataset ;\n","\n","*tips: there is a pandas method doing this right away, go read the [tutorial](https://pandas.pydata.org/docs/user_guide/10min.html) again if you do not have it yet*\n","\n","*   Propose a way to visualize relative variations of the consumption, wind and solar variables against time (this can be done in one line!)\n","\n","*tips: after normalizing between 0 and 1 all your pandas variables, plot them against time in a same figure (all this can be done on a single code line in pandas using the function DataFrame.plot() ! )*"]},{"cell_type":"markdown","metadata":{"id":"HV7zqspwrN3x"},"source":["## Dataset preparation"]},{"cell_type":"markdown","metadata":{"id":"TJqgVeQ1QOPR"},"source":["**Question 2.4** : for time series data, itâ€™s conventional to represent the time component in the index of a DataFrame. Doing this, manipulations can be performed with respect to this element.\n","\n","*   What is the current index of your DataFrame ? \n","\n","*   Using the method `pandas.to_datetime()`, parse the string values of `data['Date']` to timestamps ;\n","\n","*   Using the method `pandas.set_index()`, set `data['Date']` as the index of the `DataFrame` ;\n","\n","*   What is the dtype of `data['Date']` now ?"]},{"cell_type":"markdown","metadata":{"id":"4tLSwjLKdT_u"},"source":["**Question 2.5** : as before, we have to define a feature matrix **X** and a label vector *y*. \n","\n","As a first dummy baseline, we will implement the following simplistic model : one that predicts today's consumption value based on two predictive variables: 1) yesterday's consumption value and 2) difference between yesterday and the day before yesterday's consumption value.\n","\n","Using only `DataFrame.loc` and `DataFrame.drop` methods, build a feature matrix `X` with these two variables, named `Yesterday` and `Yesterday_Diff`. \n","\n","*tips: use the [`shift()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shift.html) and [`diff()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) methods*\n","\n","\n","The label vector `y` will be directly defined as the `Consumption` variable.\n","\n","Be carefull to drop all the NaN values within your dataset (`DataFrame.dropna` method)."]},{"cell_type":"markdown","metadata":{"id":"cXaJ76PfOlCu"},"source":["## Evaluation protocol"]},{"cell_type":"markdown","metadata":{"id":"gZaX0xsQR8wX"},"source":["**Question 2.6** : to build your training and test sets, you will be using 10 years of data for training, i.e. 2006-2016, and last year's data for testing, i.e. 2017. Build the variables `X_train`, `y_train`, `X_test` and `y_test` following this protocol."]},{"cell_type":"markdown","metadata":{"id":"k4d-qAUGiEUy"},"source":["**Question 2.7** : for what concerns performance measures, we will be using the Root Mean Squared Deviation, defined as\n","\n","\\begin{equation}\n"," RMSD = \\sqrt{\\frac{\\sum_{i=1}^{N}{\\Big( x_{1,i} -x_{2,i} \\Big)^2}}{N}}\n","\\end{equation}\n","\n","Create a function `def rmsd(y_true, y_pred):` implementing this metric."]},{"cell_type":"markdown","metadata":{"id":"JkqsppO5VrXx"},"source":["## Model evaluation"]},{"cell_type":"markdown","metadata":{"id":"tIwes3Q0A__W"},"source":["**Question 2.8** : your evaluation will benchmark two machine learning models: a [Lasso linear](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and a [KNn regressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) model. \n","\n","Drawing from the previous evaluation and using sklearn implementations, perform this evaluation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s5PqoAyVyk9I"},"source":["# SOURCES:\n","\n","*   Chollet, F. (2018) \"[Deep learning with python](https://www.manning.com/books/deep-learning-with-python)\", Manning Publications **(available at the library of ENSTA Bretagne)**\n","\n","*   https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1\n","\n","*   https://petebankhead.gitbooks.io/imagej-intro/content/chapters/bit_depths/bit_depths.html\n","\n"]}]}